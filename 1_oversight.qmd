# Human Agency and Oversight

Respect for human autonomy encompasses respect for a democratic, flourishing, and equitable society. This involves the prioritization of user agency and necessitating human oversight of the AI system. This requirement is particularly important for AI systems which guide or influence human decision-making---and is thus of central importance to the STRATIF-AI project. 

**Definitions:**
human-in-the-loop (HITL): capability for human intervention in every decision cycle of the system
human-on-the-loop (HOTL): capability for human intervention during the design cycle of the system and monitoring the system's operation
human-in-command (HIC): capability to oversee the overall activity of the AI system (including its broader economic, societal, legal and ethical impact) and the ability to decide when and how to use the AI system in any particular situation---e.g., override decision or discontinue use

## Human agency and autonomy

### ALTAI assessment {.unnumbered}

STRATIF-AI is intended to guide decisions made by human end-users---i.e., both doctors and patients---, and these decisions are in turn projected to impact the decisions of end-users (patients' health and autonomy, as well as doctors' autonomy) and society in general. To ensure STRATIF-AI does not generate confusion about the extent the allocation of epistemic authority, a plan to disseminate information in an accessible manner to a diversity of end-users will be necessary. The risk of interpretation of a digital twin as a human rather than AI system is potentially low, but a risk assessment needs to be made to rule out this possibility. The risk of addiction or unhealthy attachment to the system are again deemed low, but measures to mitigate or minimize the risk of such activities need to be developed. The risk of manipulation needs to be investigated. 

### Define epistemic authority

**Description**  In the events where there is a ***discrepancy*** between the predictions of the tool and the medical opinion of the doctor, a process protocol for epistemic authority dilemmas customized for ***physician expertise level*** must be described.  

***discrepancy:*** difference in recommended course of treatment; difference in output *from existing medical device*;  
***physician expertise level:*** early; proficient; expert  

**Owner**  

- WP4
- WP5
- WP6

**Key Personnel**

- WP3
-   medical staff *TBD*
-   design staff *TBD*

**Schedule**  At any point, before end of project.  

**Stroke Phase** EACH (3)

**Actionable tasks**  

* appoint key personnel
* define discrepancy
* clarify if comparison of AI and clinician will be conducted in clinical study
* pilot study quantify discrepancy
* assess discrepancy
* prepare process protocol outline
* define physician expertise levels
* completion of process protocol
* feedback from medical staff
* publication/research design about epistemic authority

### Explain model output

**Description** A ***methodology*** for measuring and communicating ***model output*** to ***end-users*** must be established and ***validated***.

***valid methodology:*** *set of ways in which predictions will be shown in platform*   
***model output:*** *e.g. behavioural recommendations, biomarkers, simulations*  
***end-users***: medical professionals, patients   
***validated:*** validated in clinical setting; validated in external clinical setting; validated through feedback from   experts

**Owner**  

-   WP2

**Key Personnel**

- medical staff (TBD)
- technical staff
- design staff

**Schedule**  At any point, before end of project.  

**Stroke Phase** EACH (3)

**Actionable tasks**  

* appoint key personnel
* define methods to communicate prediction interval
* validation of methods
* feedback from medical staff
* feedback from patients and patient representatives
* development of front-end communication for patients with specific conditions, age, education
* publication of validation and methodology

### Foster patient autonomy   

**Description**  A standardized ***procedure*** for explaining ***risks*** customized for patient ***subgroups*** must be designed.  

***procedure:*** video; written material; training protocol for medical staff;  
***risks:*** procedures for epistemic authority; HIC governance structure; AI system overview    
***subgroups:*** *speaking different languages; different education levels; different age groups; degree of disability*  

**Schedule**  At any point, before end of project.  

**Stroke Phase** EACH (3)

**Owner**  

* WP7

**Key Personnel**

* patient representatives
* technical staff (TBD)
* design staff (TBD)

**Actionable tasks**

* appoint key personnel
* draft documentation
* feedback from patients/patient representatives
* translation of documentation
* adaptation in simple and complex format
* adaptation for youth
* adaptation for visually impaired
* adaptation for mentally impaired
* assessment by disability experts
* additional feedback from patients/patient representatives

### Establish degree of trust

**Description** Degree of ***trust*** in the STRATIF-AI platform, determined by ***end-users***, will be assessed.

***trust:*** *TBD; operational definitions of trust*  
***end-users:*** medical professionals; patients with stroke; patients at risk of stroke; patients without stroke  

**Schedule**  At any point, before end of project. 

**Stroke Phase** ALL

**Owner**  

* WP3

**Key Personnel**

* patient representatives
* medical staff

**Actionable tasks**

* appoint key personnel
* define degrees of trust or conception of trust
* design questionnaire/interview to survey trust of system
* pre-register survey
* execute survey with key personnel
* report outcomes
* translate outcomes for end-users in platform
* disseminate outcomes in STRATIF-AI pilot studies and solicit feedback
* publication on trust in digital twins

## Human oversight

### ALTAI assessment {.unnumbered}

STRATIF-AI will be constructed as a Human-in-Command system. Medical professionals will be trained to exercise oversight according to a process protocol that has been validated. A system to detect and report misuse or adverse effects of the system will be implemented, and autonomy in predictions needs to be specified to ensure human oversight of the type of prediction generated. 

### Establish HIC governance

**Description**  Tool is designed with ***capabilities*** to enable a Human in Command (HIC) governance structure.    

***capbilities***:  oversee the overall activity of the AI system; ability to decide whether, when and how to use the system in any particular situation; ability to override a decision made by a system

**Owner**  

* WP3

**Key Personnel**

* WP7
* design staff *TBD*

**Schedule**  At any point, before end of project.  

**Stroke Phase** ALL

**Actionable tasks**  

* appoint key personnel
* create governance structure draft
* disseminate structure
* feedback from medical staff and implementation staff
* publication/research design about epistemic authority 

### Institute reporting feedback loop

**Description** A system for ***end-users*** to make reports about ***discrepancies*** should be established within the platform and ***periodically*** be evaluated. 

***end-users:*** medical professionals, patients    
***discrepancies:*** disagreement between system   recommendation and end-user decision; end-user discomfort with system recommendation; indication of errors  
***periodically:*** *TBD*  

**Stroke Phase** ALL

**Owner**  

* WP2

**Key Personnel**

* design staff
* technical staff

**Actionable tasks**

* appoint key personnel
* determine evaluation schedule
* design and validate system

### Manage patient expectations 

**Description** In the events where there is a ***discrepancy*** between the predictions of the tool and the perspective or opinion of the patient, a process protocol for managing expectations, customized for patients of different ***subgroups*** must be described.

***discrepancy:*** *acceptable threshold for difference based on previously defined discrepancy types*. 
***subgroups:*** *stroke risk category; age groups; education levels; degree of disability*. 

**Owner**  

- WP4
- WP5
- WP6

**Key Personnel**

-   medical staff *TBD*

**Schedule**  At any point, before end of project.  

**Stroke Phase** EACH (3)

**Actionable tasks**  

* completion of process protocol
* report number of discrepancies
* feedback on process protocol from medical staff
* feedback on process protocol from patient representatives

::: {.callout-note}
This requirement is closely related to 1.1.1; 1.1.2; and 1.2.2. Requirement 1.2.2 will enable reporting discrepancies for patients, and the execution of 1.1.2 will inform the process protocol for this requiremnt.
:::

### Enable autonomy of end-users

**Description** ***End-users*** should have sufficient control over platform ***parameters*** to foster independent use and trust in the system predictions. 

***end-users:*** medical staff, patients   
***parameters:*** predictive model type; stroke type; *data to be used for predictions; data to be ommitted for predictions;*   

**Owner**

- WP2

**Key Personnel**

- medical staff *TBD*
- technical staff *TBD*
- design staff *TBD*

**Schedule**  At any point, before end of project.  

**Stroke Phase** EACH (3)

**Actionable tasks**  

* appoint key personnel
* determine parameters which can be controlled at end-use
* design interface to select parameters
* feedback from medical staff
* feedback from patients

