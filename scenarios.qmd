# Socio-technical Description {.unnumbered}

The description of socio-technical scenarios is a tool adapted from the Z-inspection audit process, which is a validation process designed to support AI development projects. A socio-technical description is both useful and necessary to situate ethical challenges for the STRATIF-AI project and the solutions outlined in this manual. The sections were informed by participant observation of STRATIF-AI bi-annual and bi-monthly meetings, as well as facilitation of the a co-creation workshop series with consortium members. 

## System Aims
Context, why is the system used, goal

## Actors

### Primary 
Directly involved with use of AI system

### Secondary/Tertiary
Indirectly involved with use of AI system

Who designed and implemented the system? Who has authorized the deployment of the system? Who is currently using the system? Who are the end users for this system? Who is directly influenced by decisions made by the system? Who is indirectly influenced by decisions made by the system? Who is responsible for this system?

### Expectations and Motivations
Why would the different groups of actors want the system? What are their expectations towards the system behavior? What benefits are they expecting from using the system?

### Concerns
What problems / challenges can the actors foresee? Do they have concerns regarding the use of the system? What risks are they concerned about with the system? Are there any conflicts?

## Context of AI system
What additional context information about the situation where the AI system is used? (e.g. urgency, budget constraints, for profit, academic, conflicts, environmental). What are potential future usage of the AI system?

## Human Interaction
What is the intended interaction between the system and its users? If and how the 'human in control' aspect is envisaged? Why is it like this?

## AI Technology
Technical description of the AI system. An important part of considering AI trustworthiness is that it is robust and if the technical description is not clear, this cannot be assessed.

## Clinical studies
Was the system's performance validated in (clinical/field tests) studies? What were the results of these studies? Are the results openly available?

## Intellectual Property
What parts of the AI system are open access (if any)? What IP regulations need to be considered when assessing / disseminating the system? Does it contain confidential information that must not be published? What is and how to handle the IP of the AI and of the part of the system to be examined. Identify possible restrictions to the Inspection process, in this case, assess the consequences (if any) Define if and when Code Reviews are needed/possible.

## Legal Framework 
What is the legal framework for use of the system? What special regulations apply? What are the data protection issues?", "Was the data aspect compliant with the GDPR?

## Ethics Oversight
Did they get a waiver? Was there a clearing, but it was very light or internal and not considered sufficient?

