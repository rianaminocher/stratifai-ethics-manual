# Accountability

The principle of accountability highlights the need to establish mechanisms to guarantee responsibility throughout the lifecycle of AI systems. This principle intersects closely with risk management practices, which involve transparently identifying and mitigating risks that can be comprehended and audited by external parties. In instances where unjust or adverse impacts arise, accessible mechanisms for accountability must be established, to facilitate the opportunity for redress to affected parties.

**Keywords:**  
accountability, AI Ethics Review Board, redress by design

## Auditability

### ALTAI Assessment {.unnumbered}

The auditability of STRATIF-AI's workflow and system lifecycle is a fundamental aspect of our ethical plan. By creating a living document, we aim to establish a transparent and traceable log of all measures taken to adhere to ethical principles and legal requirements. To ensure the AI system can be audited by independent third parties, the ethical plan will be made available or disseminated accordingly. 

### Facilitate auditability

**Description** ***Means*** to facilitate external audits of STRATIF-AI processes will be instituted and validated.

**Means:*** A publicly available and version-controlled ethical plan; *any additional implementation strategies?*

**Owner**  

* WP3

**Key Personnel**

* WP7
* WP2

**Schedule**  At any point, before end of project.  

**Stroke Phase** ALL

**Actionable tasks**  

* appoint key personnel
* define additional outputs?
* discuss site prototype and any legal barriers
* solicit feedback on prototype
* create sub-page to report important parameters
* define important parameters
* e.g. traceability of the development process, the sourcing of training data and the logging of the AI systemâ€™s processes, outcomes, positive and negative impact
* make pages public

## Tradeoffs/ Risk-management

### ALTAI Assessment {.unnumbered}

Ensuring both the ability to report on actions or decisions contributing to the outcomes of AI systems and to address the consequences of such outcomes is paramount. It is essential to identify, assess, document, and mitigate potential negative impacts of AI systems, particularly for those directly or indirectly affected. Safeguards must be in place to protect whistleblowers, NGOs, trade unions, and other entities reporting legitimate concerns about AI systems. As part of WP3 within the STRATIF-AI project, we will conduct an external Z-inspection assessment, which is a gold-standard and validated methodology to assess the ethical impacts of an AI tool. A comprehensive risk training protocol will be designed and adhere to any legal protocols. Our ethical plan has been designed in concordance with the Assessment List for Trustworthy AI (ALTAI), and, as such, will be continually evaluated throughout the AI system's lifecycle. 

While implementing these requirements, tensions may arise, necessitating inevitable trade-offs. We will identify relevant interests and values implicated by the AI system and explicitly evaluate trade-offs in terms of their risk to safety and ethical principles, including fundamental rights. These decisions will be thoroughly documented throughout our ethical audit process. Additionally, a  a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system, and a following risk management protocol will be instituted. Accessible mechanisms to ensure adequate redress will be established.

### Institute external reporting system

**Description** A system for ***third-parties*** to make reports about ***risks*** should be established within the platform and ***periodically*** be evaluated.

***third-parties:*** citizens; hospital workers; developers; *any contributors of technology or data*   
***risks:***  vulnerabilities; errors; concerns   
***periodically:*** *TBD*   

**Stroke Phase** ALL

**Owner**  

* WP2

**Key Personnel**

* design staff
* technical staff
* WP3

**Actionable tasks**

* appoint key personnel
* define all parameters
* define link to feedback reporting loop
* implement/design procedure
* feedback from third parties to validate
* test system

### Collect post-prediction feedback

**Description** A system for ***end-users*** to provide feedback about ***medical applicability*** should be established within the platform. This is closely related to the requirement under Section [Human Agency and Oversight](1_oversight.qmd); Institute reporting feedback loop.

***end-users:*** medical professionals  
***medical applicability:*** effectiveness; relevance; alignment with evolving medical knowledge and practices; 

**Stroke Phase** EACH (3)

**Owner**  

* WP4
* WP5
* WP6

**Key Personnel**

* medical staff
* design staff
* technical staff

**Actionable tasks**

* appoint key personnel
* medical professionals to define key parameters
* prototype for system/information parameters
* implementation by WP2/ design staff
* design and validate system

### Conduct budget impact analysis

**Description** The economic justification of the implementation of the STRATIF-AI platform for different ***stakeholders*** must be made via cost-benefit analyses.

***stakeholders:*** hospitals; insurance companies; patients; rehab centers; *any affected institutional parties?*

**Stroke Phase** EACH (3)

**Owner**  

* WP7

**Key Personnel**

* medical staff

**Actionable tasks**

* appoint key personnel
* define parameters 
* design budget impact/ cost-benefit analysis study
* conduct analysis
* report results
* publication/dissemination of results
