# Introduction {.unnumbered}

The integration of artificial intelligence (AI) in healthcare presents several ethical challenges, which may have implications for the protection of fundamental human rights. Dedicated efforts are essential to ensure that AI systems in healthcare adhere to principles of lawfulness, ethics, and robustness. To address these challenges within the STRATIF-AI project, we develop a plan which outlines steps to mitigate ethical risks and increase trustworthiness throughout the AI development process. To construct this plan, we draw on interdisciplinary expertise and utilize three core strategies:

**(1) Operationalization:** Existing guidelines or soft-law documents tend to be rather high-level or generally applicable, which makes them appropriate for a diversity of AI systems. As a consequence, overarching principles must be contextualized into actionable steps, which are specifically tailored to the characteristics of a particular AI system. We utilize expertise on ethical framework building to ensure that legal guidelines do not remain theoretical concepts, but are rather effectively integrated into the design, deployment, and ongoing management of the AI system. For the STRATIF-AI project, this will enable identification of potential ethical risks early in the project lifecycle, to ultimately enhancing its trustworthiness and societal benefit.

**(2) Co-creation:** To ensure the equitable development of solution, content for this manual is being co-created with relevant stakeholders within the STRATIF-AI project, i.e., clinicians, data scientists, medical researchers, patient organization representatives and project coordinators. We thus assess the risks and benefits of various requirements to ensure ethics and trustworthiness, to create necessary, feasible and auditable ethical requirements. 

**(3) Anticipation:** STRATIF-AI introduces several novel technological solutions, which may not fall within the scope of previously enumerated ethical guidelines. A hybrid machine-learning and mechanistic modelling framework will be utilized to simulate patient specific responses to changes in behaviour, diet, exercise and medication. Models will be trained on diverse sources of electronic health data, collected from 6 clinical studies, within a federated learning platform. Data will be uploaded and stored in a Personal Data Vault—to ensure patient control—and subjected to a semantic harmonization process to make themminteroperable. Such a multi-faceted technology is yet unprecedented and could indeed spur new ethical dilemmas. Solutions based solely on existing regulations will be reactive rather than prescriptive, having to rely on the deployment and failure of technology to guide decision-making. To pre-empt such changes, we are conducting a scoping review of the ethical considerations in the field of digital twin technology in health-care.
