[
  {
    "objectID": "7_accountability.html#auditability",
    "href": "7_accountability.html#auditability",
    "title": "7  Accountability",
    "section": "7.1 Auditability",
    "text": "7.1 Auditability\n\nALTAI Assessment\nThe auditability of STRATIF-AI’s workflow and system lifecycle is a fundamental aspect of our ethical plan. By creating a living document, we aim to establish a transparent and traceable log of all measures taken to adhere to ethical principles and legal requirements. To ensure the AI system can be audited by independent third parties, the ethical plan will be made available or disseminated accordingly.\n\n\n7.1.1 Facilitate auditability\nDescription Methodology to facilitate external audits of STRATIF-AI processes will be instituted and validated.\nMethodology: A publicly available and version-controlled ethical plan; TBD\nvalidated: validated by Z-inspection process; validated within Delphi study\nOwner\n\nWP3\n\nKey Personnel\n\nWP7\nWP2\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine additional outputs?\ndiscuss site prototype and any legal barriers\nsolicit feedback on prototype\ncreate sub-page to report important parameters\ndefine important parameters\ne.g. traceability of the development process, the sourcing of training data and the logging of the AI system’s processes, outcomes, positive and negative impact\nmake pages public\n\n\n\n7.1.2 Adhere to ethical/open research norms\nDescription Research work produced by the STRATIF-AI consortium must adhere to EU Horizon funding guidelines as well as ethical norms regarding the data availability, reproducibility, open access, distribution, confidentiality and originality of published work.\ndata availability: data made available in Zenodo repository; data adheres to FAIR principles; data is labelled as clearly associated research publication\nreproducibility: scientific code is made available on Github; scientific code is made available on Zenodo\nopen access: research published under “gold” open access standards; research published in journal with CC-BY license\ndistribution: authorship roles are allocated within CRediT taxonomy; fraudulent authorship is prevented (“guest”, “gift”, “ghost”); authors meet minimum authorship criteria;\nconfidentiality: sensitive information about patients is protected; permission from primary author must be obtained before dissemination;\noriginality: use of any AI-assisted technology is disclosed; reference to published/unoriginal work is appropriately cited;\n\n\n\n\n\n\nNote\n\n\n\nFurther information on the CRediT taxonomy for assigning authorship is available online at https://credit.niso.org. The Royal Society Publishing Editorial team also provides tips on publishing ethics here https://royalsociety.org/blog/2022/03/authorship-contributions-disputes-misconduct/.\n\n\nOwner\n\nWP3\n\nKey Personnel\n\nall WP leads\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ncreate publication guide, to be signed before publication by authors\nimplement SOP for publication within consortium"
  },
  {
    "objectID": "7_accountability.html#tradeoffs-risk-management",
    "href": "7_accountability.html#tradeoffs-risk-management",
    "title": "7  Accountability",
    "section": "7.2 Tradeoffs/ Risk-management",
    "text": "7.2 Tradeoffs/ Risk-management\n\nALTAI Assessment\nIt is essential to identify, assess, document, and mitigate potential negative impacts of AI systems, particularly for those directly or indirectly affected. Safeguards must be in place to protect whistleblowers, NGOs, trade unions, and other entities reporting legitimate concerns about AI systems. As part of WP3 within the STRATIF-AI project, we will conduct an external Z-inspection assessment, which is a gold-standard and validated methodology to assess the ethical impacts of an AI tool. A comprehensive risk training protocol will be designed and adhere to any legal protocols. Our ethical plan has been designed in concordance with the Assessment List for Trustworthy AI (ALTAI), and, as such, will be continually evaluated throughout the AI system’s lifecycle.\nWhile implementing these requirements, tensions may arise, necessitating inevitable trade-offs. We will identify relevant interests and values implicated by the AI system and explicitly evaluate trade-offs in terms of their risk to safety and ethical principles, including fundamental rights. These decisions will be thoroughly documented throughout our ethical audit process. Additionally, a a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system, and a following risk management protocol will be instituted. Accessible mechanisms to ensure adequate redress will be established.\n\n\n7.2.1 Institute external reporting system\nDescription A system for third-parties to make reports about risks should be established within the platform and periodically be evaluated.\nthird-parties: citizens; hospital workers; developers; any contributors of technology or data\nrisks: vulnerabilities; errors; concerns\nperiodically: TBD\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ndesign staff\ntechnical staff\nWP3\n\nActionable tasks\n\nappoint key personnel\ndefine all parameters\ndefine link to feedback reporting loop\nimplement/design procedure\nfeedback from third parties to validate\ntest system\n\n\n\n\n\n\n\nNote\n\n\n\nIn relation to requirement 6.3.1, it will be necessary to solicit and encourage feedback from non-users and potential users to mitigate risks of misuse or under-user of the STRATIF-AI platform.\n\n\n\n\n7.2.2 Collect post-prediction feedback\nDescription A system for end-users to provide feedback about medical applicability should be established within the platform.\n\n\n\n\n\n\nNote\n\n\n\nThis is closely related to the requirement 1.2.2 Human Agency and Oversight; Institute reporting feedback loop.\n\n\nend-users: medical professionals\nmedical applicability: effectiveness; relevance; alignment with evolving medical knowledge and practices;\nStroke Phase EACH (3)\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nmedical staff\ndesign staff\ntechnical staff\n\nActionable tasks\n\nappoint key personnel\nmedical professionals to define key parameters\nprototype for system/information parameters\nimplementation by WP2/ design staff\ndesign and validate system\n\n\n\n7.2.3 Conduct budget impact analysis\nDescription The economic justification of the implementation of the STRATIF-AI platform for different stakeholders must be made via cost-benefit analyses.\nstakeholders: hospitals; insurance companies; patients; rehab centers; any affected institutional parties?\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\nmedical staff\n\nActionable tasks\n\nappoint key personnel\ndefine parameters\ndesign budget impact/ cost-benefit analysis study\nconduct analysis\nreport results\npublication/dissemination of results"
  },
  {
    "objectID": "framework.html#design-and-use",
    "href": "framework.html#design-and-use",
    "title": "Framework",
    "section": "Design and Use",
    "text": "Design and Use\nOur framework has been designed to be a living document, and, as such, will be revised following upcoming workshops, audits, and through external validation.\nThe contents of the first version of the framework were developed based on a series of co-creation workshops (see: Workshops).\nPlanned updates to the framework will follow (1) a focused stakeholder workshop series, (2) upcoming audits of current framework adherence and (3) an external Z-inspection of the AI system.\n(1) A focused stakeholder workshop series will be conducted to complete the requirements outlined in this document. More specifically, some requirements have been planned according to the current expertise, knowledge, and timeline, but still lack specific information about parameters, methods, key personnel or planned output. These details will be completed in an iterative process during the forthcoming workshop series.\n(2) Audits are planned at five time points during the project, at 6-month increments, to assess adherence to the framework, nominate potential challenges, and suggest changes to resolve issues.\n(3) An external Z-inspection will be conducted to assess the trustworthiness of the STRATIF-AI platform. Z-inspection is a published and validated gold standard method by which external experts use sociotechnical scenarios to derive AI trustworthiness requirements. The results of the Z-inspection process will be integrated into the framework."
  },
  {
    "objectID": "framework.html#regulatory-context",
    "href": "framework.html#regulatory-context",
    "title": "Framework",
    "section": "Regulatory Context",
    "text": "Regulatory Context\nThe Framework for Ethical and Trustworthy Design of the STRATIF-AI platform has been designed in concordance with the (1) EU Guidelines for Trustworthy AI and (2) Assessment List for Trustworthy Artificial Intelligence (ALTAI).\nThe EU Guidelines for Trustworthy AI were developed on 8 April 2019 by the High-Level Expert Group on Artificial Intelligence (AI HLEG). The guidelines aim to promote three key principles to support the development and deployment of safe AI systems—i.e., lawfulness, ethics and robustness. The principles are expounded as seven key requirements (Figure 1).\n\n\n\nEU Guidelines for Trustworthy AI. source: AI HLEG\n\n\nThe Assessment List for Trustworthy Artificial Intelligence (ALTAI) was derived on 17 July 2020 by the High-Level Expert Group on Artificial Intelligence (AI HLEG), to aid AI developers in implementing regulatory requirements in practice. This tool serves as a practical instrument for assessing the compliance of AI systems with the current legal and ethical framework."
  },
  {
    "objectID": "framework.html#structure",
    "href": "framework.html#structure",
    "title": "Framework",
    "section": "Structure",
    "text": "Structure\nOur framework is divided into seven sections, each corresponding to one of seven requirements set forth by the EU Guidelines for Trustworthy AI:\n\nHuman Agency and Oversight\nTechnical Robustness and Safety\nPrivacy and Data Governance\nTransparency\nDiversity, non-discrimination, and Fairness\nSocietal and Environmental Wellbeing\nAccountability\n\nUnder each section, we provide a preliminary assessment of the STRATIF-AI platform following the questions included in the Assessment List for Trustworthy AI (ALTAI) checklist.\nWe then describe a set of project-specific requirements. Under each project-specific requirement, we outline a set of relevant information that is either planned or requires revision.\n\n\n\n\n\n\nNote\n\n\n\nUnder each requirement, we delineate information that requires revision and will be updated following workshops/audits in italic text.\n\n\n\nRequirement Template\nDescription We describe each requirement briefly and nominate specific parameters which need to be expounded or addressed.\nparameters: We identify specific parameters within each requirement. These parameters help to add precision to the attribute, goal, or entity described by the parameter word.\n\n\n\n\n\n\nNote\n\n\n\nWhen a parameter has been defined, it is delineated by plain text. If a parameter is yet to be defined, we provide prompts which will help to define parameters in future workshops, which are delineated by italic text.\n\n\nOwner\n\nEach requirement has an “Owner”, who is responsible for its implementation.\n\nKey Personnel\n\nSeveral stakeholders may serve as key personnel to contribute to or facilitate progress towards this requirement. Named personnel are TBD and will be identified in upcoming workshops.\n\n\n\n\n\n\n\nNote\n\n\n\nSome information will need to be completed in upcoming focused stakeholder workshops and planned audits. We use TBD (to be determined) to delineate information that needs to be addressed in workshops and audits.\n\n\nSchedule A preliminary schedule will be devised.\nStroke Phase We identify whether this requirement pertains to all phases of stroke (prevention, acute treatment, rehabilitation) that the STRATIF-AI tool intends to treat.\nActionable tasks\n\nHere we list a set of tasks\nWhich will be executed\nIn order to successfully meet this requirement\nThese lists will be updated in subsequent audits\n\n\n\nRequirement Example\nDescription Explainability materials will be customized for specific end-users.\nend-users: patients; medical professionals\ncustomized: available in video format; available in written format\n\n\n\n\n\n\nTip\n\n\n\n“End-user” could refer to a variety of entities—e.g., patients or medical professionals. Parameterizing attributes, goals, or entities mentioned in requirements helps to make the requirement more flexible, less ambiguous, and easier to implement.\n\n\nOwner\n\nWP3\n\nKey Personnel\n\nWP2\nWP1\ntechnical staff TBD\nmodelling staff TBD\nmedical staff TBD\npatient representatives TBD\n\n\n\n\n\n\n\nTip\n\n\n\nTo complete this requirement, we will require input from modellers/WP2, data scientists/WP1, as well as feedback from end-users—clinicians and patients.TBD denotes that key personnel will need to be named (“to be determined”) in upcoming workshops and audits.\n\n\nSchedule At any point, before the end of the project.\nStroke Phase EACH (3)\n\n\n\n\n\n\nTip\n\n\n\nThis requirement will need to be addressed for all intended use-cases of the STRATIF-AI platform. This means that the tasks necessary to complete the requirement, and the planned output (here: video/written material), should be completed each for patients at risk of stroke (prevention phase), patients with stroke (acute phase), and patients recovering from stroke (rehabilitation phase).\n\n\nActionable tasks\n\nappoint key personnel\ncreate prototype for explainability\nfeedback from WP1/WP2/technical staff\nupdate prototype\ntranslate for different end-users\nfeedback from end-users"
  },
  {
    "objectID": "workshops.html#overview",
    "href": "workshops.html#overview",
    "title": "Co-creation Workshops",
    "section": "Overview",
    "text": "Overview\nA series of workshops were conducted with STRATIF-AI consortium members to define issues, requirements, and solutions regarding the design of an ethical and trustworthy AI system. The workshops were designed following feedback from a similar program, which was developed for the EU Horizon project “VALIDATE” and executed in 2023."
  },
  {
    "objectID": "workshops.html#schedule-and-participants",
    "href": "workshops.html#schedule-and-participants",
    "title": "Co-creation Workshops",
    "section": "Schedule and participants",
    "text": "Schedule and participants\nWorkshops were conducted in March 2024 and comprised a diversity of participants from within the STRATIF-AI consortium. The planned duration of each workshop was 3.5 hours; the final workshop duration was between 3 and 3.5 hours. All workshops, with the exception of the first, were facilitated by Riana Minocher (CUB). The first workshop was facilitated by Riana Minocher (CUB) with assistance from Gabriele Pluktaite (CUB). All consortium members who are subscribed to the STRATIF-AI email list were invited to register their participation via a Google form.\n\nDate conducted and number of participants\n\n\n\nWorkshop number\nDate conducted\nNumber of participants\n\n\n\n\n1\n05.03.2024\n6\n\n\n2\n13.03.2024\n4\n\n\n3\n20.03.2024\n4\n\n\n4\n27.03.2024\n2\n\n\n\n\n\nDetails about participants in Workshops\n\n\n\n\n\n\n\n\nWorkshop number\nBeneficiary\nPosition\n\n\n\n\n1\nTREE\nData scientist\n\n\n1\nTUD\nML scientist\n\n\n1\nZ2\nData expert\n\n\n1\nFINCB\nClinician\n\n\n1\nFINCB\nClinician\n\n\n1\nLIU (ext)\nPrevention expert\n\n\n2\nFINCB\nPsychologist\n\n\n2\nBREST\nClinician\n\n\n2\nUM\nData scientist\n\n\n2\nRV\nSimulation scientist\n\n\n3\nGUT\nRehab physician\n\n\n3\n\nClinician\n\n\n3\nSHE\nProject manager\n\n\n3\nSPF\nImplementation strategist\n\n\n4\nTUD\nData scientist\n\n\n4\nGUT\nRehabilitation therapist"
  },
  {
    "objectID": "workshops.html#methodology",
    "href": "workshops.html#methodology",
    "title": "Co-creation Workshops",
    "section": "Methodology",
    "text": "Methodology\nThe first workshop functioned as a pilot session. Resources/exercises were modified following the first session to accommodate feedback from participants and informal reflections. Participants received an email the day before the workshop with information and instructions on how to participate. Workshops were conducted on Microsoft Teams. Mural was used to disseminate materials and facilitate note-taking during discussions.\nEach workshop was divided into three sections:\n1. Introduction and warmup:\n\nIntroduction by facilitator to list workshop goals and overview\nParticipant introductions using sticky-notes in Mural\nCreativity game: to warm up and practice using Mural\n\n2. Understand concepts:\n\nFree-list in answer to prompt “What ethical concerns come to mind when you think of STRATIF-AI?”\nDiscuss EU requirements meanings/associations\nMap EU requirements to STRATIF-AI project workflow\n\n3. Define concrete requirements:\n\nDemo of STRATIF-AI framework site\nDiscuss requirements/solutions within groups\n\nThe phase “Understand concepts” was intended to serve as a primer for participants about various ethical issues that have been defined by governing bodies, and to begin to think about how such issues might be related to the STRATIF-AI project. Exposure to requirements and terminology was deemed necessary to guide discussion in the phase “Define concrete requirements”. In this phase, participants were expected to highlight project-specific concerns, which may pertain to their expertise, interest or own personal health history."
  },
  {
    "objectID": "workshops.html#output",
    "href": "workshops.html#output",
    "title": "Co-creation Workshops",
    "section": "Output",
    "text": "Output\n\nGeneral Reflections\nThe workshops were generally well-received. In Workshop 1, participants discussed topics within their expertise with enthusiasm, but some noted the insufficient time to cover all possible content. The suggestion for follow-up workshops, which could be tailored to specific stakeholder roles, was made. Workshop 2 saw broad awareness of potential risks and discussion of potential abuse of AI within healthcare. Workshop 3 faced some technical challenges, due to difficulties with using Mural effectively, but this did not prevent a serious discussion about risks, roles and responsibilities. Finally, Workshop 4 engaged only two participants, but of complementary backgrounds, which fostered a detailed discussion about the trade-offs between data protection and model performance. Overall, the workshops provided valuable insights and highlighted the need for ongoing dialogue about ethical considerations within the STRATIF-AI project.\n\n\nKey Themes\nDiscussion during workshops highlighted several recurrent themes that appeared important to resolve. We summarize these below to help contextualize the content of different requirements within the Framework for Ethical and Trustworthy Design of the STRATIF-AI platform (See: Framework).\n\nData Ownership: Participants discussed considerations regarding data ownership, re-use, quality, and bias extensively. They emphasized the importance of patient data control, particularly regarding stewardship of data in the event of death or disability, the potential to re-use data for studies, the process of obtaining informed consent for data use, and the novel challenges presented by the data harmonization and federated learning processes.\nTransparency: A significant focus was placed on ensuring transparency in AI systems to empower patients and clinicians, and maintain their trust. Discussions highlighted the challenge of effectively conveying the meaning behind technical terms such as “prediction uncertainty” to citizens. Similarly, the challenge of developing transparent models which are accessible to clinicians and patients of varying goals and experience was discussed.\nPatient Empowerment: Discussion in workshops underscored the importance of patient empowerment in the AI-driven healthcare landscape. Participants emphasized the need for patients to have control over their data, and for AI systems to provide understandable and actionable insights to empower informed decision-making. The need to communicate insights without causing harm to mental or emotional wellbeing was identified.\nPersonalized Prevention: Participants emphasized the significance of a user-centric approach, especially in tailoring prevention programs to diversity of end-users. In addition to fostering patient control, physicians should also have autonomy over the type of model and outcome used to make predictions. The potential benefits of personalized health coaching through digital twins were also discussed as potentially driving behavioral change and contributing to broader societal wellbeing.\nA Common Language for Health: Several participants raised the importance of integrating discussions across diverse stakeholder groups and defining a common language for health. Addressing disparities in health literacy and ensuring equitable distribution of AI platforms across communities were highlighted as key considerations."
  },
  {
    "objectID": "1_oversight.html#human-agency-and-autonomy",
    "href": "1_oversight.html#human-agency-and-autonomy",
    "title": "1  Human Agency and Oversight",
    "section": "1.1 Human agency and autonomy",
    "text": "1.1 Human agency and autonomy\n\nALTAI assessment\nSTRATIF-AI is intended to guide decisions made by human end-users—i.e., both doctors and patients—, and these decisions are in turn projected to impact the decisions of end-users (patients’ health and autonomy, as well as doctors’ autonomy) and society in general. To ensure STRATIF-AI does not generate confusion about the extent the allocation of epistemic authority, a plan to disseminate information in an accessible manner to a diversity of end-users will be necessary. The risk of interpretation of a digital twin as a human rather than AI system is potentially low, but a risk assessment needs to be made to rule out this possibility. The risk of addiction or unhealthy attachment to the system are again deemed low, but measures to mitigate or minimize the risk of such activities need to be developed. The risk of manipulation needs to be investigated.\n\n\n1.1.1 Define epistemic authority\nDescription In the events where there is a discrepancy between the predictions of the tool and the medical opinion of the doctor, a process protocol for epistemic authority dilemmas customized for physician expertise level must be described.\ndiscrepancy: difference in recommended course of treatment; difference in output from existing medical device;\nphysician expertise level: early; proficient; expert\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nWP3\nmedical staff TBD\ndesign staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine discrepancy\nclarify if comparison of AI and clinician will be conducted in clinical study\npilot study quantify discrepancy\nassess discrepancy\nprepare process protocol outline\ndefine physician expertise levels\ncompletion of process protocol\nfeedback from medical staff\npublication/research design about epistemic authority\n\n\n\n1.1.2 Explain model output\nDescription A methodology for measuring and communicating model output to end-users must be established and validated.\nvalid methodology: set of ways in which predictions will be shown in platform\nmodel output: e.g. behavioural recommendations, biomarkers, simulations\nend-users: medical professionals, patients\nvalidated: validated in clinical setting; validated in external clinical setting; validated through feedback from experts\nOwner\n\nWP2\n\nKey Personnel\n\nmedical staff (TBD)\ntechnical staff\ndesign staff\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine methods to communicate prediction interval\nvalidation of methods\nfeedback from medical staff\nfeedback from patients and patient representatives\ndevelopment of front-end communication for patients with specific conditions, age, education\npublication of validation and methodology\n\n\n\n1.1.3 Foster patient autonomy\nDescription A standardized procedure for explaining risks customized for patient subgroups must be designed.\nprocedure: video; written material; training protocol for medical staff;\nrisks: procedures for epistemic authority; HIC governance structure; AI system overview\nsubgroups: speaking different languages; different education levels; different age groups; degree of disability\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\npatient representatives\ntechnical staff (TBD)\ndesign staff (TBD)\n\nActionable tasks\n\nappoint key personnel\ndraft documentation\nfeedback from patients/patient representatives\ntranslation of documentation\nadaptation in simple and complex format\nadaptation for youth\nadaptation for visually impaired\nadaptation for mentally impaired\nassessment by disability experts\nadditional feedback from patients/patient representatives\n\n\n\n1.1.4 Establish degree of trust\nDescription Degree of trust in the STRATIF-AI platform, determined by end-users, will be assessed.\ntrust: TBD; operational definitions of trust\nend-users: medical professionals; patients with stroke; patients at risk of stroke; patients without stroke\nSchedule At any point, before end of project.\nStroke Phase ALL\nOwner\n\nWP3\n\nKey Personnel\n\npatient representatives\nmedical staff\n\nActionable tasks\n\nappoint key personnel\ndefine degrees of trust or conception of trust\ndesign questionnaire/interview to survey trust of system\npre-register survey\nexecute survey with key personnel\nreport outcomes\ntranslate outcomes for end-users in platform\ndisseminate outcomes in STRATIF-AI pilot studies and solicit feedback\npublication on trust in digital twins"
  },
  {
    "objectID": "1_oversight.html#human-oversight",
    "href": "1_oversight.html#human-oversight",
    "title": "1  Human Agency and Oversight",
    "section": "1.2 Human oversight",
    "text": "1.2 Human oversight\n\nALTAI assessment\nSTRATIF-AI will be constructed as a Human-in-Command system. Medical professionals will be trained to exercise oversight according to a process protocol that has been validated. A system to detect and report misuse or adverse effects of the system will be implemented, and autonomy in predictions needs to be specified to ensure human oversight of the type of prediction generated.\n\n\n1.2.1 Establish HIC governance\nDescription Tool is designed with capabilities to enable a Human in Command (HIC) governance structure.\ncapbilities: oversee the overall activity of the AI system; ability to decide whether, when and how to use the system in any particular situation; ability to override a decision made by a system\nOwner\n\nWP3\n\nKey Personnel\n\nWP7\ndesign staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ncreate governance structure draft\ndisseminate structure\nfeedback from medical staff and implementation staff\npublication/research design about epistemic authority\n\n\n\n1.2.2 Institute reporting feedback loop\nDescription A system for end-users to make reports about discrepancies should be established within the platform and periodically be evaluated.\nend-users: medical professionals, patients\ndiscrepancies: disagreement between system recommendation and end-user decision; end-user discomfort with system recommendation; indication of errors\nperiodically: TBD\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ndesign staff\ntechnical staff\n\nActionable tasks\n\nappoint key personnel\ndetermine evaluation schedule\ndesign and validate system\n\n\n\n1.2.3 Manage patient expectations\nDescription In the events where there is a discrepancy between the predictions of the tool and the perspective or opinion of the patient, a process protocol for managing expectations, customized for patients of different subgroups must be described.\ndiscrepancy: acceptable threshold for difference based on previously defined discrepancy types. subgroups: stroke risk category; age groups; education levels; degree of disability.\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nmedical staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\ncompletion of process protocol\nreport number of discrepancies\nfeedback on process protocol from medical staff\nfeedback on process protocol from patient representatives\n\n\n\n\n\n\n\nNote\n\n\n\nThis requirement is closely related to 1.1.1; 1.1.2; and 1.2.2. Requirement 1.2.2 will enable reporting discrepancies for patients, and the execution of 1.1.2 will inform the process protocol for this requiremnt.\n\n\n\n\n1.2.4 Enable autonomy of end-users\nDescription End-users should have sufficient control over platform parameters to foster independent use and trust in the system predictions.\nend-users: medical staff, patients\nparameters: predictive model type; stroke type; data to be used for predictions; data to be ommitted for predictions;\nOwner\n\nWP2\n\nKey Personnel\n\nmedical staff TBD\ntechnical staff TBD\ndesign staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndetermine parameters which can be controlled at end-use\ndesign interface to select parameters\nfeedback from medical staff\nfeedback from patients"
  },
  {
    "objectID": "2_technical.html#resilience-to-attack-and-security",
    "href": "2_technical.html#resilience-to-attack-and-security",
    "title": "2  Technical Robustness and Safety",
    "section": "2.1 Resilience to attack and security",
    "text": "2.1 Resilience to attack and security\n\nALTAI Assessment\nIn the event of technical faults, misuse or defect, STRATIF-AI could have damaging effects to human safety. The risk of vulnerability to cyber-attacks will be evaluated to ensure the system is made compliant with security standards under the Cybersecurity Act in Europe. Vulnerability to data poisoning, model evasion, model inversion will be addressed throughout model validation and testing. Measures to ensure robustness to attacks after the system has been deployed will be designed. The expected timeframe of validity for security measures need to be defined.\n\n\n2.1.1 Define risks of Federated Learning\nDescription Measures to assess whether federated learning exposes patients to risks must be established, assessed and reported.\nrisks: model inversion (information in parameters to reconstruct data); data leakage; data poisoning\nOwner\n\nWP1\n\nKey Personnel\n\ntechnical staff TBD\n\nSchedule During model training.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine list of risks and parties\ndocument measures to assess risks\nverify metrics are sufficient to dissuade concerns about vulnerability\npublish validation study\n\n\n\n2.1.2 Comply with cybersecurity law\nDescription The system must be made compliant with the relevant cybersecurity norms and legislation.\nrelevant cybersecurity norms and legislation: EU; country-specific; global\nOwner\n\nWP7\n\nKey Personnel\n\ntechnical staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine relevant legislation/ compliance categories\n\n\n\n2.1.3 Establish emergency protocols\nDescription In the event of a breach to security, a process protocol based on the severity and type of attack must be followed.\nseverity: TBD define metrics to measure security breach, and scale of severity\ntype: data poisoning; model evasion; TBD define types\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\nWP7\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine severity levels for attack\ndefine parameters for process protocols\nexternal validation of process protocols"
  },
  {
    "objectID": "2_technical.html#general-safety",
    "href": "2_technical.html#general-safety",
    "title": "2  Technical Robustness and Safety",
    "section": "2.2 General safety",
    "text": "2.2 General safety\n\nALTAI Assessment\nThe risks associated with the AI system for each use-case will be assessed through pilot and clinical studies. Procedures to continuously measure and access risks will be devised, validated and implemented. A plan to inform end-users of existing and potential risks will be made. STRATIF-AI is a novel concept and technology; possible threats and vulnerability to misuse should additionally be explored through additional research. Stability and reliability of the system will continually be assessed throughout model development. A plan to regularly evaluate the system, upon changes to technical infrastructure, will also be devised.\n\n\n2.2.1 Assess risk of use\nDescription An independent risk assessment of use of the STRATIF-AI platform for different end-users must be carried out.\nrisk assessment: a standardized risk assessment must be designed\nend-users: patients; patients with stroke; patients at risk of stroke; patients without stroke; language; education; age; disability; medical professionals; doctors; physiotherapists; psychologists; care-workers; proficiency-levels; learner; proficient; expert\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nmedical staff TBD\npatients/patient representatives TBD\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine end-users and risk assessment framework\ndevelop protocol for clinical study/pilot study\nconduct risk assessment\npublish risk assessment\n\n\n\n\n\n\n\nNote\n\n\n\nThis requirement will focus on creating a general risk assessment for the tool. The requirement 2.1.1 is additionally necessary to specifically define the risks of data leakage or vulnerability to attack due to the Federated Learning process. Thus, requirement 2.1.1 will likely feed into the general risk assessment necessitated here.\n\n\n\n\n2.2.2 Implement risk-assessment feedback loop\nDescription A system to assess and report risk customized for end-users should be established within the platform and periodically be evaluated.\nrisk: risks from risk asessment must be mapped; threat to safety; threat to validity; risk of misuse; issues with reliability;\nend-users: medical professionals; patients\nperiodically: TBD\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ndesign staff\ntechnical staff\nWP3\n\nActionable tasks\n\nappoint key personnel\ndetermine evaluation schedule\ntranslate risk assessment risk types\ndefine parameters\nprototype\nvalidate system\n\n\n\n\n\n\n\nNote\n\n\n\nA system for feedback reporting, with both automated and non-automated components, must be designed and integrated into the STRATIF-AI platform, to address several requirements together, including this one.\n\n\n\n\n2.2.3 Communicate risks to patients\nDescription A standardized procedure for explaining risks of the system customized for patients of different subgroups must be designed.\nprocedure: video; written material; training protocol for medical staff;\ntechnical risks: to define risks for patients\npatients: language capabilities; educational experience; age groups; degree/type of disability;\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\npatient representatives\ntechnical staff TBD\ndesign staff TBD\nWP3\n\nActionable tasks\n\nappoint key personnel\ndefine technical risks\ndraft documentation\nfeedback from patients/patient representatives\ntranslation of documentation\nadaptation in simple and complex format\nadaptation for youth\nadaptation for visually impaired\nadaptation for mentally impaired\nassessment by disability experts\nadditional feedback from patients/patient representatives\n\n\n\n\n\n\n\nNote\n\n\n\nTo address several requirements, including this one, a comprehensive set of patient subgroups will need to be defined, which should include all potentially vulnerable or marginalized patient profiles.\nThis requirement is closely related to requirement 1.1.3\n\n\n\n\n2.2.4 Derive process protocol for technical updates\nDescription A process protocol for assessing system functions following system updates should be designed and followed.\nsystem functions: validity; risks to safety; precision; other metrics to assess system performance\nsystem updates: periodic changes, error reporting, feedback reporting\nSchedule At any point, before end of project.\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\ndesign staff TBD\n\nActionable tasks\n\nappoint key personnel\ndefine regular system function metrics\ndesign process protocol\nfeedback from experts/ external review\ndissemination of protocol"
  },
  {
    "objectID": "2_technical.html#accuracy",
    "href": "2_technical.html#accuracy",
    "title": "2  Technical Robustness and Safety",
    "section": "2.3 Accuracy",
    "text": "2.3 Accuracy\n\nALTAI Assessment\nEffective and safe use of the STRATIF-AI platform hinges upon a high level of accuracy. Measures to ensure data is of high quality, representative, and continuously monitored for accuracy will be put in place. The external and internal validity of the system will be established and periodically reviewed. Levels of accuracy and validity established for the STRATIF-AI platform will clearly be communicated to end-users.\n\n\n2.3.1 Evaluate data accuracy within Federated Learning\nDescription The accuracy of the Federated Learning system under different scenarios must be analyzed and monitored periodically.\nscenarios: missing data; data interoperability; heterogeneity of data; updates to data types\nperiodically: TBD\nSchedule At any point, before end of project.\nStroke Phase ALL\nOwner\n\nWP1\n\nKey Personnel\n\ntechnical staff TBD\n\nActionable tasks\n\nappoint key personnel\ndefine scenarios to assess validity\ndefine periodic intervals for assessment\ndesign system\n\n\n\n2.3.2 Evaluate accuracy of model predictions\nDescription The accuracy of the model output under different scenarios must be analyzed and monitored periodically.\nmodel output: prediction; biomarkers; simulations\nscenarios: missing data; data interoperability; heterogeneity of data; updates to data types\nperiodically: TBD\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\n\nActionable tasks\n\nappoint key personnel\ndefine scenarios to assess validity\ndefine periodic intervals for assessment\ndesign system\n\n\n\n2.3.3 Establish internal validity\nDescription The behaviour of the tool, based on a set of core performance metrics will not differ under different data contexts.\nperformance metrics: sensitivity; specificity; area-under-curve; error reporting frequency\ndata contexts: TBD; split of training data\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff (TBD)\nWP3\npatients/patient representatives\n\nActionable tasks\n\nverify whether this is planned in clinical studies\nappoint key personnel\ndefine performance metrics\ndefine data contexts to assess\ndesign study protocol\nfeedback from patient representatives\nvalidate in pilot study\npublish validation\n\n\n\n2.3.4 Establish external validity\nDescription The model output of should not differ across patient end-users of different subgroups.\nmodel output: prediction; biomarkers; simulations\nsubgroups: patient subgroups; geography; ethnicity; gender; socio-economic background; health history; disability;\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\nWP3\nWP7\npatient representatives\n\nActionable tasks\n\nappoint key personnel\ndefine patient subgroups\ndefine performance metrics\ndesign study for external validation\nfeedback on study design\npublication of external validity\n\n\n\n\n\n\n\nNote\n\n\n\nThe implementation of this requirement is closely related to several requirements under the section Diversity, non-discrimination and Fairness."
  },
  {
    "objectID": "2_technical.html#reliability-and-reproducibility",
    "href": "2_technical.html#reliability-and-reproducibility",
    "title": "2  Technical Robustness and Safety",
    "section": "2.4 Reliability and reproducibility",
    "text": "2.4 Reliability and reproducibility\n\nALTAI Assessment\nReliability and reproducibility will play a crucial role along the entire STRATIF-AI workflow. Reproducibility metrics will be defined and evaluated periodically. Methods of verification of reproducibility/reliability will clearly be documented. A procedure to track errors and trace their source will be developed. A continual learning system to adapt system performance to evolving medical guidelines or diverse medical principles will also be instated.\n\n\n2.4.1 Track system errors\nDescription A system to track, trace, and report errors within the platform must be implemented.\nerrors TBD; different types of output and internal errors\nSchedule At any point, before end of project.\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\ndesign staff TBD\n\nActionable tasks\n\nappoint key personnel\ndefine error reporting metrics\ndesign error reporting system\nverification by technical experts\npublication (internal) of system\npublication of reports\n\n\n\n2.4.2 Ensure continuous adaptation\nDescription Measures to ensure that the system is able to adapt to evolving treatment guidelines while maintaining predictive accuracy will be taken.\n\n\n\n\n\n\nNote\n\n\n\nThis addresses data scarcity challenges and handling variations in healthcare practices, particularly in countries with different approaches to guideline adherence.\n\n\nevolving treatment guidelines: variation in healthcare practice; countries with different guidelines; changing regulations\npredictive accuracy: acceptable range TBD\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\ntechnical staff (TBD)\ndesign staff (TBD)\nWP3\n\nActionable tasks\n\nappoint key personnel\ndefine boundaries for predictive accuracy/acceptable range\ndefine evolving treatment guidelines\ndevelop process protocol for evaluation\n\n\n\n\n\n\n\nNote\n\n\n\nSeveral requirements, including this one, refer to the predictive accuracy of the output; this parameter will be defined through the implementation of requirements1.1.2 and 2.3.2."
  },
  {
    "objectID": "3_privacy.html#privacy",
    "href": "3_privacy.html#privacy",
    "title": "3  Privacy and Data Governance",
    "section": "3.1 Privacy",
    "text": "3.1 Privacy\n\nALTAI Assessment\nIn the event of data leakage or misuse, STRATIF-AI could have significant impacts on the rights to privacy, physical, mental and moral integrity, and data protection. A process protocol to report violations to privacy or data integrity must be developed and implemented.\n\n\n3.1.1 Investigate right to privacy within Federated Learning\nDescription The Federated Learning platform transfers model parameters rather than data; vulnerabilities of the system for data privacy must be quantified.\nvulnerabilities: potential to reconstruct training data; glean private information; model inversion\nquantified: levels of security to be identified\nOwner\n\nWP1\n\nKey Personnel\n\nWP2\nmodelling staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\nidentify potential vulnerabilities\nidentify metrics to quantify scale/severity of vulnerability\nassess performance\npublish results\n\n\n\n\n\n\n\nNote\n\n\n\nThis requirement is closely linked to requirement 2.1.1.\n\n\n\n\n3.1.2 Allocate data usage and access rights\nDescription Design for different data types detailing access and safeguards for vulnerable patient groups must be made available within the Data Management Plan.\ndata types: training data; Personal Data Vault\naccess: rights to access; location of storage; potential to re-use; encryption\nsafeguards: stewardship upon death; stewardship in event of disability; stewardship of carers/wards\nvulnerable patient groups: speaking different languages; age groups; ethnicity; disability\nOwner\n\nWP1\n\nKey Personnel\n\nWP7 TBD\npatient representatives TBD\nWP4 TBD\nWP5 TBD\nWP6 TBD\n\nSchedule At any point, before end of project.\n\n\n\n\n\n\nNote\n\n\n\nThe STRATIF-AI project includes a Data Management Plan (DMP) as a recurring deliverable. This requirement will be addressed within the scope of upcoming DMPs.\n\n\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\nreview current data management plan and details\nidentify patient subgroups; access types; safeguards\nfeedback on DMP from patient representatives\nfeedback from medical professionals\nmake plan publicly and internally available/within apps/platform\n\n\n\n3.1.3 Implement feedback system\nDescription A system with relevant specifications to flag violations must be implemented within the platform and a corresponding process protocol drawn up.\nrelevant specifications: TBD\nviolations: TBD; violation to privacy; violation to data integrity;\nOwner\n\nWP2\n\nKey Personnel\n\ndesign staff\nWP1 TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndesign system\ndraft process protocol\nfeedback on prototype by end-users"
  },
  {
    "objectID": "3_privacy.html#data-governance",
    "href": "3_privacy.html#data-governance",
    "title": "3  Privacy and Data Governance",
    "section": "3.2 Data governance",
    "text": "3.2 Data governance\n\nALTAI Assessment\nSTRATIF-AI is trained using personal healthcare records and will be continually informed by private and securely transferred data within the Personal Data Vault. A Data Protection Impact Assessment will be executed, relevant Data Protection Officers will be appointed, and the requirements under General Data Protection Regulation will be adhered to. In addition, mechanisms to ensure oversight of data processing, data transformation and data harmonization within the Federated Learning environment will be drafted. Data minimization possibilities will need to be investigated. The right to withdraw consent, right to object, and right to be forgotten will be revised and communicated to end-users. The AI system will be aligned with relevant standards and widely adopted protocols within the relevant regulatory framework.\n\n\n3.2.1 Assess data quality\nDescription A quality control system to ensure different data types fulfill quality critera will be implemented and made available to end-users before use for model training or prediction.\ndata type: training data; Personal Data Vault\nquality criteria: robust to missing data; robust to inaccuracies; robust to input errors; additional criteria and pre-defined thresholds\nend-users: patients; medical professionals\nOwner\n\nWP1\n\nKey Personnel\n\ndesign staff TBD\ntechnical staff TBD\nWP1 TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine quality control metrics and acceptable thresholds\nupdate any existing process protocols\nproduce quantitative assessments for existing data/prototype data\ntranslate assessment for end-users\n\n\n\n3.2.2 Standardize data preparation procedures\nDescription The procedures involved in manipulating training data for Federated Learning across project partners must be standardized.\nprocedures: pre-processing; evaluation; forecasting; validation; ML monitoring\npartners: each hospital/data contributor\nstandardized: created in a format/schema/protocol\nOwner\n\nWP1\n\nKey Personnel\n\ntechnical staff TBD\nWP4\nWP5\nWP6\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine set of procedures\nidentify partner set and any potential need for discrepancies/specific operationalization\nstandardize procedures through iterative process with partners\naudit adherence\nreport adherence and publish procedures\n\n\n\n3.2.3 Standardize data harmonization procedures\nDescription The parameters of the harmonization process for making data interoperable must be defined and be reviewed periodically.\nparameters: drift detection; retraining procedure; relevant ontologies periodically: TBD\nOwner\n\nWP1\n\nKey Personnel\n\ntechnical staff TBD\nWP4\nWP5\nWP6\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine parameters for harmonization process\ncreate SOP for harmonization so this information is available to partners\nfeedback from partners\n\n\n\n\n\n\n\nNote\n\n\n\nDuring co-creation workshops, a lack of clarity about the data harmonization process, particularly when new patient data is added, emerged. How the harmonization process will be governed after the model training procedure is complete must be clarified within this requirement.\n\n\n\n\n3.2.4 Acquire informed consent\nDescription A process protocol for obtaining consent must be drafted, which outlines access rights, restrictions once consent has been provided, and is tailored to specific patient subgroups.\naccess rights: which physicians/medical staff will have access; stewardship in event of disability; patient subgroups: language; age; education; disability\nrestrictions: withdraw consent; right to object; right to be forgotten; how will models be retrained if consent is withdrawn;\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nWP3\nWP1 TBD\nmedical staff\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndraft consent forms\ndefine parameters for forms\ntailor to each stroke phase\nfeedback from patient representatives\n\n\n\n3.2.5 Adhere to GDPR\nDescription Relevant requirements under General Data Protection Regulation must be adhered to.\nrelevant requirements: TBD\nOwner\n\nWP1\n\nKey Personnel\n\nTBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\ncheck if this is part of DMP\ncreate additional document providing translation for patients/end-users\n\n\n\n3.2.6 Investigate data minimization\nDescription The costs of collecting intimate data from patients must be balanced against violation of patient trust, and validated by appropriate methodology.\ncosts: perceived harm; erosion of trust\nviolation of patient trust: operational definition of trust, threshold for violation\nmethodology: cost-benefit analysis; qualitative judgement; Delphi consensus\nOwner\n\nWP3\n\nKey Personnel\n\nWP4 TBD\nWP5 TBD\nWP6 TBD\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nincorporate in trust study\nresearch about potential data minimization\nelicit patient/expert feedback on costs/benefits of highly invasive data"
  },
  {
    "objectID": "4_transparency.html#traceability",
    "href": "4_transparency.html#traceability",
    "title": "4  Transparency",
    "section": "4.1 Traceability",
    "text": "4.1 Traceability\n\nALTAI Assessment\nTraceability is difficult to achieve for complex data-driven AI systems. STRATIF-AI will be engineered with measures to enable traceability of the system as far as possible. The ability to trace back data, data quality, and decision rules of the system will be quantified, assessed, and reported to end-users. The decisions of the system and the associated “quality” of such decisions will be continuously monitored.\n\n\n4.1.1 Enable system traceability\nDescription The ability to trace back key system parameters will be assessed systematically and translated for a diversity of end-users.\nsystem parameters: data source; data demographics; patient-specific data; model parameters; model calibration metrics;\nassessed: a system within the platform to report data\nend-users: medical professionals; patients;\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\nmedical staff TBD\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine system parameters that should be identified\ndesign platform/system to assess/enable info\nfeedback from end-users on system and params\ntranslation of outputs\nfeedback from end-users on interpretability of output\npublication of traceability system\n\n\n\n4.1.2 Quality control of predictions\nDescription The decisions of the system must be systematically compared with human feedback to infer prediction quality.\ndecisions: predictions; prediction intervals; data output\nsystematically compared: design of study comparison\nhuman feedback: discrepancy with medical decision; patient discomfort;\nquality: construct a quality score\nOwner\n\nWP2\n\nKey Personnel\n\nWP3\ntechnical staff TBD\nmedical staff TBD\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine decisions to be recorded and feedback format\ndesign platform within app to do so\nconstruct quality score\nstudy design and preregistration\npublication of quality of decisions/ update to system\n\n\n\n\n\n\n\nNote\n\n\n\nThis requirement is closely connected with requirements under section Human Agency and Oversight."
  },
  {
    "objectID": "4_transparency.html#explainability",
    "href": "4_transparency.html#explainability",
    "title": "4  Transparency",
    "section": "4.2 Explainability",
    "text": "4.2 Explainability\n\nALTAI Assessment\nSTRATIF-AI is a clinical decision support-system. Both doctors and medical professionals must be provided with a reasonable understanding of the decisions made by the system.\n\n\n4.2.1 Provide decision-making parameters to end-users\nDescription Information about the relevant parameters that led to an algorithmic decision will be validated and available in a simplified format to end-users.\nsimplified format: video; written material; user interface\nparameters: modelling parameters; training data parameters; Data Vault parameters;\nend users: medical professionals; patients;\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\ndesign staff TBD\nmedical staff TBD\npatient representatives TBD\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine parameters\ninterview/feedback from key personnel\ncreate in-app design\nfeedback on prototype in pilot study\n\n\n\n4.2.2 Monitor explainability\nDescription Establishing the explainability of the STRATIF-AI platform could serve as a blueprint for digital-twin based/personalized medicine projects. The satisfaction of end-users with the explainability of the platform over the course of its use should be continuously monitored.\nsatisfaction: measured as suitability of explanatory materials/information; combined with feedback reporting loop;\nend-users: medical professionals; experience levels; patients; education; age; language; disability;\nOwner\n\nWP2\n\nKey Personnel\n\nWP7\ntechnical staff TBD\nmedical staff TBD\npatient representatives TBD\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndecide on study or in-app reporting system\ndefine satisfaction criteria\ndesign and validate system\ncombine with feedback reporting loop?\n\n\n\n4.2.3 Assess costs of model explainability\nDescription The costs of explainability for the model parameters and decision-rules will be traded off against their accuracy. During model development and training such costs should be systematically assessed and recorded.\ncosts: TBD; format to quantify explainability versus accuracy tradeoff;\nOwner\n\nWP2\n\nKey Personnel\n\nWP3\ntechnical staff TBD\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine explainability metrics\ndesign system to record/assess\nis this part of existing modelling protocol\npublication of explainability/accuracy tradeoff assessment\ntranslation of materials for end-users"
  },
  {
    "objectID": "4_transparency.html#communication",
    "href": "4_transparency.html#communication",
    "title": "4  Transparency",
    "section": "4.3 Communication",
    "text": "4.3 Communication\n\nALTAI Assessment\nThere is little risk of the AI system being interpreted as a human. However, the HIC governance concept must be clearly communicated to end-users. The benefits, technical limitations, potential risks must additionally be communicated to end-users in a transparent and explainable manner. A comprehensive training protocol for end-users—particularly medical personnel—must be developed in collaboration with the system developers.\n\n\n4.3.1 Standardize training materials\nDescription Instructions about appropriate application of the STRATIF-AI must be adapted for a end-users of different subgroups.\nappropriate application: technical limitations; potential risks; error rates; evidence-based health benefits;\nadapted: available as written manual; flyer; video\nend-users: medical professionals; patients\nsubgroups: experience levels; patients; education; age; language; disability\nOwner\n\nWP7\n\nKey Personnel\n\ntechnical staff (TBD)\nmedical staff (TBD)\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine proper use parameters\ninterview/feedback from key personnel\nmake prototype written and flyer materials\noutsource video/audio materials\ntranslation for disability, language, education, age\npublication of materials\n\n\n\n4.3.2 Tailor explainability material\nDescription An overview of STRATIF-AI system functions and outputs will be communicated in a diversity of formats, designed specifically for end-users of different subgroups.\nfunctions: modelling framework; modelling maps; decision-making process; training data; private data vault; security protocols; human oversight; evidence of efficacy; rationale for using tool; ] outputs: TBD; model output formats: available as written manual; video; flyer;\nend-users: medical professionals; patients\nsubgroups: education; age; language; disability\nOwner\n\nWP3\n\nKey Personnel\n\nWP7\ntechnical staff TBD\nmedical staff TBD\npatient representatives\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine parameters\ninterview/feedback from key personnel\nrefine content\nmake prototype written and flyer materials\noutsource video/audio materials\ntranslation for disability, language, education, age\npublication of materials\n\n\n\n\n\n\n\nNote\n\n\n\nRequirements 4.3.1 and 4.3.2 are closely related. Requirement 4.3.1 involves the creation of training materials for use of the platform, i.e., serving as the guide for use, while Requirement 4.3.2 will deliver the explainability materials, i.e., serving as a background or primer on the AI system."
  },
  {
    "objectID": "5_diversity.html#avoidance-of-unfair-bias",
    "href": "5_diversity.html#avoidance-of-unfair-bias",
    "title": "5  Diversity, Non-discrimination and Fairness",
    "section": "5.1 Avoidance of unfair bias",
    "text": "5.1 Avoidance of unfair bias\n\nALTAI Assessment\nThroughout development, consideration will be given to the diversity and representativeness of end-users and subjects within training data. Testing protocols will be tailored to rectify potential biases, to ensure integrity and impartiality of the platform across user demographics and application scenarios. Educational initiatives aimed at cultivating awareness among AI designers and developers regarding bias and its ethical ramifications will be initiated, fostering a culture of accountability. Mechanisms for identifying and resolving issues pertaining to bias or discrimination within the STRATIF-AI platform will be established within clear communication channels. Discourse with impacted communities, particularly at-risk patient subgroups, will be conducted to ensure that the STRATIF-AI project consortium’s conception of fairness resonates with diverse perspectives. A quantitative analytical framework will be embraced to measure and evaluate the efficacy the applied definition of fairness, and institute mechanisms to achieve as such.\n\n\n5.1.1 Represent diversity in training data\nDescription Inclusive representation of patients of specific (under-represented) subgroups in training data will be assessed against an acceptable threshold and rectified or reported accordingly.\nsubgroups: patients; patients with stroke; patients at risk of stroke; patients without stroke; language; education; age; disability; ethnicity; gender; migration status; socio-economic status;\nthreshold: reasonable representation; if zero; report in prediction uncertainty\nOwner\n\nWP4\nWP5\nWP6\n\nKey Personnel\n\nmedical staff TBD\npatients/patient representatives TBD\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine at-risk patient subgroups\ndefine acceptable thresholds\nfeedback from patient representatives/experts\nassess training data\nreport in publication\nnote challenge of oversimplified categorization\n\n\n\n5.1.2 Monitor bias\nDescription A system to periodically monitor bias in different project stages must be implemented.\nsystem: prototype for system\nperiodically: TBD\nstages: training data preparation; federated learning; model tweaking; prediction modelling\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\nWP4\nWP5\nWP6\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ncreate bias testing pipelines\ndefine parameters\nsend pipelines to necessary spaces (e.g., clinical partners)\npilot bias testing in preliminary study\nreport output\npublication of tool/pipeline\n\n\n\n5.1.3 Assess prediction bias\nDescription System outputs will be assessed to ensure there is no acceptable difference between patient subgroups.\noutputs: model output parameters; discrepancy\ndifference: TBD; quantitative threshold; acceptable margin of error;\nsubgroups gender; sex; ethnicity; education; health history; disability; socio-economic background\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine parameters model outputs\ndefine patient subgroups\ndefine thresholds\nfeedback on thresholds\npublication of results\n\n\n\n5.1.4 Implement bias reporting system\nDescription A system for end-users to make reports about bias should be established within the platform and periodically be evaluated.\nend-users: medical professionals, patients\nbias: any discrimination; process protocol for what constitutes bias; response;\nperiodically: TBD\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff TBD\ndesign staff\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndetermine evaluation schedule\noutline process protocol for updates upon substantial bias\ndesign and validate system\n\n\n\n5.1.5 Cultivate ethical awareness\nDescription A strategy to ensure awareness about ethical issues and accountability for the system, tailored to specific stakeholders, will be designed and executed.\nstrategy: workshop series; training programme; accountability declaration;\nstakeholders: developers; doctors; clinicians; care-workers; patients; family members; technical designers; project managers;\nOwner\n\nWP3\n\nKey Personnel\n\nall relevant leads\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nwrite up workshop paper\ncreate training package materials\ninterview study with experts\ndesign accountability declaration for project partners\npublish memorandum\n\n\n\n5.1.6 Assess fairness across use-setting\nDescription The fairness of system outputs across different use-settings needs to be quantitatively evaluated to minimize risk of unfair prediction values for specific locations/services.\noutputs: prediction intervals; prediction types; accessibility; speed;\nuse-settings: hospitals; homes; resource differences; medical equipment; medical staff;\nOwner\n\nWP7\n\nKey Personnel\n\nWP4\nWP5\nWP6\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndesign study to assess fairness across contexts\ndefine parameters to study\npre-register study\npilot with prototype of tool or collect data within clinical trials\npublication of results\n\n\n\n5.1.7 Assess and build trust within vulnerable patient groups\nDescription Degree of trust in the STRATIF-AI platform, determined by end-users, will be quantified. An assessment of trust within specifically vulnerable patient and care-work subgroups will be assessed and measures to respond to discrepancies between subgroups devised.\ntrust: TBD; operational definition of trust\nend-users: medical professionals; patients with stroke; patients at risk of stroke; patients without stroke\nsubgroups: language; education; age; disability; ethnicity; gender; migration status; socio-economic status;\nSchedule At any point, before end of project.\nStroke Phase ALL\nOwner\n\nWP3\n\nKey Personnel\n\npatient representatives\nmedical staff\n\nActionable tasks\n\nappoint key personnel\ndefine degrees of trust or conception of trust\ndesign questionnaire/interview to survey trust of system\npre-register survey\nexecute survey with key personnel\nreport outcomes\nassess how outcomes vary within patient subgroups\ndisseminate outcomes in STRATIF-AI pilot studies and solicit feedback\npublication on trust and diversity in digital twins\n\n\n\n\n\n\n\nNote\n\n\n\nThis requirement will constitute a part of the trust study designed to fulfill Requirement 1.1.4 Establish degree of trust.\n\n\n\n\n5.1.8 Implement fairness reporting system\nDescription A system to report whether the system outputs are evaluated as accessible must be implemented within the platform for end-users.\noutputs: prediction intervals; recommendations; rehab demos;*\naccessible: comprehensible in language; available to varying levels of resource access; feasible within time budgets;\nend-users: patients; medical staff\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\npatient representatives\nmedical staff\ndesign staff TBD\n\nActionable tasks\n\nappoint key personnel\ndefine parameters output and feasibility\nprototype system in apps/platform\npilot study\nreport results\npublication"
  },
  {
    "objectID": "5_diversity.html#accessibility-and-universal-design",
    "href": "5_diversity.html#accessibility-and-universal-design",
    "title": "5  Diversity, Non-discrimination and Fairness",
    "section": "5.2 Accessibility and universal design",
    "text": "5.2 Accessibility and universal design\n\nALTAI Assessment\nMeasures to prioritize inclusivity and accessibility of STRATIF-AI to a wide and diverse user-base will be taken. Assessment will be conducted to gauge the usability of the AI system’s user interface for individuals with special needs, disabilities, or those at risk of exclusion. Efforts will be made to guarantee that information about the AI system, as well as its user interface, remains accessible and usable for users of assistive technologies, particularly those relevant for patients of stroke. Furthermore, Universal Design principles will be integrated into various stages of planning and development, where applicable, to enhance accessibility for all users.\n\n\n5.2.1 Utilize inclusive design principles\nDescription The platform must be designed, tested, and trained by methods to account for needs of vulnerable subgroups of end-users.\nmethods: TBD needs: TBD\nend-users: medical staff; patients;\nsubgroups: language; ethnicity; socio-economic background; health history; trust;\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP3\n\nKey Personnel\n\npatient representatives TBD\nmedical staff TBD\ndesign staff TBD\n\nActionable tasks\n\nappoint key personnel\nthis will move to a different owner after preliminary assessment\ndefine set of needs that should be accessible\nidentify different patient subgroups\nconduct interviews/solicit patient feedback\ndesign protocol to evaluate prototype design\nmove WP owner to design staff\npilot design and solicit feedback\n\n\n\n5.2.2 Assess financial risk of unfair design\nDescription The system outputs must be critically evaluated to avoid risks of financial misuse in different clinical settings.\noutputs: prediction intervals; discrepancy between clinician and prediction; discrepancy between patient and clinician;\nrisks: insurance system; financial overhead; costs of stay\nclinical settings: hospitals; rehab centers\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP7\n\nKey Personnel\n\npatient representatives\nmedical staff\ndesign staff (TBD)\ntechnical staff (TBD)\n\nActionable tasks\n\nappoint key personnel\ndefine parameters\nperform evaluation\ne.g., via experimental study/ pilot/ lit review\nupdate outputs\ninstitute necessary data protections"
  },
  {
    "objectID": "5_diversity.html#stakeholder-participation",
    "href": "5_diversity.html#stakeholder-participation",
    "title": "5  Diversity, Non-discrimination and Fairness",
    "section": "5.3 Stakeholder participation",
    "text": "5.3 Stakeholder participation\n\nALTAI Assessment\nSTRATIF-AI is a project with a significant diversity in stakeholders. Consistent feedback and co-creation will be maintained with stakeholders during early stages of project development. Mechanisms to ensure sustained stakeholder involvement after the implementation of the platform will also be designed.\n\n\n5.3.1 Incorporate patient perspectives\nDescription Feedback and perspectives about system functions from representatives of patient subgroups will be solicited periodically and incorporated into system development.\nsubgroups: gender; disability; ethnicity; socio-economic status\nperiodically: TBD\nfunctions: model output, prediction intervals; design; overall trust; use;\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nOwner\n\nWP3\n\nKey Personnel\n\npatient representatives\n\nActionable tasks\n\nappoint key personnel\ndefine parameters\ndesign study or format\ndesign a reproducible questionnaire that can easily be answered\npass to WP4, WP5, WP6\ndesign process protocol for responding to feedback\ndesign procedure for disseminating feedback\npublication on patient perspectives\n\n\n\n5.3.2 Foster end-user feedback\nDescription A system for end-users to provide feedback should be established within the platform and periodically be evaluated.\nend-users: medical professionals, patients;\ndiscrepancies: format of feedback;\nperiodically: TBD;\nStroke Phase ALL\nOwner\n\nWP2\n\nKey Personnel\n\ndesign staff\ntechnical staff\n\nActionable tasks\n\nappoint key personnel\ndetermine evaluation schedule\ndesign and validate system\n\n\n\n\n\n\n\nNote\n\n\n\nRequirements 5.2.1; 5.3.1; and 5.3.2 are closely related. Requirement 5.2.1 is concerned with design of the platform for end-users who may be patients or medical staff with diverse accessibility needs. Requirement 5.3.1 is concerned with more general inclusivity of specifically patients in the overall development and goals of the STRATIF-AI platform. Requirement 5.3.2 refers to a feedback system—again closely linked with several other requirements—to provide information to enable the fulfillment of requirements 5.2.1 and 5.3.1."
  },
  {
    "objectID": "6_societal.html#environmental-wellbeing",
    "href": "6_societal.html#environmental-wellbeing",
    "title": "6  Societal and Environmental Well-being",
    "section": "6.1 Environmental Wellbeing",
    "text": "6.1 Environmental Wellbeing\nAI systems should be as environmentally friendly as possible. The development, deployment and use-processes must therefore be assessed in terms of energy consumption and resource demands, in order to minimize waste. During the development of the STRATIF-AI project, the potential of negative harm on the environment needs to be systematically considered. Measuring the environmental impact through energy consumed and carbon emissions will be built into the development pipeline. Measures to reduce these impacts will be subsequently explored.\n\n6.1.1 Identify environmental impact of model development\nDescription The environmental impacts of system development processes need to be measured or estimated by appropriate methodologies.\nenvironmental impacts: carbon emissions; energy used;\nsystem development processes: model training; other process with footprint?\nmethodologies: TBD\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine parameters (environmental and possibly costly processes)\ndefine method to estimate costs\nreport costs to consortium/in documentation\n\n\n\n6.1.2 Reduce environmental impact\nDescription A SOP which outlines acceptable thresholds and a resulting process protocol must be developed within an appropriate timeframe to mitigate environmental impacts.\nthresholds: limit for carbon emissions for model training; limit for time spent model training\nappropriate timeframe: TBD\nOwner\n\nWP2\n\nKey Personnel\n\ntechnical staff\nWP3\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel\ndefine parameters/ thresholds and procedures\ndraft SOP (WP3)\ndevelop SOP for modelling team\npublish SOP"
  },
  {
    "objectID": "6_societal.html#impact-on-work-and-skills",
    "href": "6_societal.html#impact-on-work-and-skills",
    "title": "6  Societal and Environmental Well-being",
    "section": "6.2 Impact on Work and Skills",
    "text": "6.2 Impact on Work and Skills\n\nALTAI Assessment\nSTRATIF-AI will be designed with a human-in-command governance system and to prioritize the epistemic authority of physicians. However, as a clinical decision-support system, STRATIF-AI will potentially have significant impacts on human work and work arrangements, necessitating a thorough assessment through an implementation strategy. While medical professionals will play a central role in the development pipeline of STRATIF-AI, broader inclusion and consultation with potentially affected workers and their representatives will be carried out. Measures to minimize the system’s impact on human work will be implemented, following an in-depth investigation of STRATIF-AI’s potential risks regarding the de-skilling of doctors or the alteration of training procedures and experiential learning.\n\n\n6.2.1 Investigate impact on work arrangements\nDescription Methodology to assess concerns of potentially affected workers must be devised to inform the platform’s implementation strategy.\nmethodology: TBD; stakeholder interviews; workshops; focus groups\nconcerns: TBD; de-skilling; mistrust\nworkers: doctors; nurses; insurance personnel; training personnel; rehabilitation specialists; physiotherapists; any affected working persons involved in the care of stroke patients\nOwner\n\nWP3\n\nKey Personnel\n\nWP4\nWP5\nWP6\nWP7\n\nSchedule At any point, before end of project.\nStroke Phase EACH (3)\nActionable tasks\n\nappoint key personnel\ndefine full set of at-risk workers\nconduct workshops with key personnel\ndesign interview to elicit concerns from workers\nwrite process protocol for implementation strategy\nfeed into HIC concept\n\n\n\n\n\n\n\nNote\n\n\n\nIn the initial co-creation workshop series, participants expressed concerns that integrating the STRATIF-AI platform into clinical practice too early and without warning may limit the natural experience-building process that physicians generally undergo."
  },
  {
    "objectID": "6_societal.html#impact-on-society-at-large-or-democracy",
    "href": "6_societal.html#impact-on-society-at-large-or-democracy",
    "title": "6  Societal and Environmental Well-being",
    "section": "6.3 Impact on Society at large or Democracy",
    "text": "6.3 Impact on Society at large or Democracy\n\nALTAI Assessment\nPotential ramifications on society at large and democracy will be considered throughout the STRATIF-AI project cycle. To assess the societal impact of the AI system’s utilization beyond those to immediate end-users and subjects, we will solicit feedback throughout planned pilot and clinical trial studies. A key aspect of the STRATIF-AI platform is developing an infrastructure to empower citizens to monitor their overall health and wellbeing while screening for risk of stroke—which will contribute to the benefit of society at large. The STRATIF-AI platform is not at risk of undermining democratic principles or adversely affecting democracy.\n\n\n6.3.1 Solicit citizen feedback\nDescription Include diverse citizens in discussions at relevant stages of the STRATIF-AI pipeline.\ncitizens: citizens; hospital workers; persons who may be overlooked in stakeholder discussions\nstages: TBD; public representation of STRATIF-AI project; youtube; reddit\nOwner\n\nWP3\n\nKey Personnel\n\nall WP leads\n\nSchedule At any point, before end of project.\nStroke Phase ALL\nActionable tasks\n\nappoint key personnel/ WP leads\ndefine parameters, i.e. stakeholders who may be overlooked\nclarify potential procedures within WP tasks to incorporate discussions\nassess input from stakeholders\ndisseminate information"
  },
  {
    "objectID": "wp_tasks.html",
    "href": "wp_tasks.html",
    "title": "Work Packages",
    "section": "",
    "text": "Work Package 1\nSemantic interoperability and federated learning platform\nSTRATIF-AI platform development and hybrid modelling\nEthical and trustworthy design\nPrevention\nAcute treatment and monitoring\nRehabilitation and follow-up of chronic condition\nCoordination, Dissemination, Implementation, and exploitation"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety",
    "href": "wp_tasks.html#technical-robustness-and-safety",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nResilience to attack and security\nDefine risks of Federated Learning\nAccuracy\nEvaluate data accuracy within Federated Learning"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance",
    "href": "wp_tasks.html#privacy-and-data-governance",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nPrivacy\nInvestigate right to privacy within Federated Learning\nAllocate data usage and access rights\nData governance\nAssess data quality\nStandardize data preparation procedures\nStandardize data harmonization procedures\nAdhere to GDPR"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight",
    "href": "wp_tasks.html#human-agency-and-oversight",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nExplain model output\nHuman oversight\nInstitute reporting feedback loop\nEnable autonomy of end-users"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety-1",
    "href": "wp_tasks.html#technical-robustness-and-safety-1",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nResilience to attack and security\nEstablish emergency protocols\nGeneral safety\nImplement risk-assessment feedback loop\nDerive process protocol for technical updates\nAccuracy\nEvaluate accuracy of model predictions\nEstablish internal validity\nEstablish external validity\nReliability and reproducibility\nTrack system errors"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance-1",
    "href": "wp_tasks.html#privacy-and-data-governance-1",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nPrivacy\nImplement feedback system"
  },
  {
    "objectID": "wp_tasks.html#transparency",
    "href": "wp_tasks.html#transparency",
    "title": "Work Packages",
    "section": "Transparency",
    "text": "Transparency\nTraceability\nEnable system traceability\nQuality control of predictions\nExplainability\nProvide decision-making parameters to end-users\nMonitor explainability\nAssess costs of model explainability"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nMonitor bias\nAssess prediction bias\nImplement bias reporting system\nStakeholder participation\nFoster end-user feedback"
  },
  {
    "objectID": "wp_tasks.html#societal-and-environmental-well-being",
    "href": "wp_tasks.html#societal-and-environmental-well-being",
    "title": "Work Packages",
    "section": "Societal and Environmental Well-being",
    "text": "Societal and Environmental Well-being\nEnvironmental Wellbeing\nIdentify environmental impact of model development\nReduce environmental impact"
  },
  {
    "objectID": "wp_tasks.html#accountability",
    "href": "wp_tasks.html#accountability",
    "title": "Work Packages",
    "section": "Accountability",
    "text": "Accountability\nTradeoffs/ Risk-management\nInstitute external reporting system\nCollect post-prediction feedback"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight-1",
    "href": "wp_tasks.html#human-agency-and-oversight-1",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nEstablish degree of trust\nHuman oversight\nEstablish HIC governance"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance-2",
    "href": "wp_tasks.html#privacy-and-data-governance-2",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nData governance\nInvestigate data minimization"
  },
  {
    "objectID": "wp_tasks.html#transparency-1",
    "href": "wp_tasks.html#transparency-1",
    "title": "Work Packages",
    "section": "Transparency",
    "text": "Transparency\n4.3. Communication\nTailor explainability material"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness-1",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness-1",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nCultivate ethical awareness\nAssess and build trust within vulnerable patient groups\nAccessibility and universal design\nUtilize inclusive design principles\nStakeholder participation\nIncorporate patient perspectives"
  },
  {
    "objectID": "wp_tasks.html#societal-and-environmental-well-being-1",
    "href": "wp_tasks.html#societal-and-environmental-well-being-1",
    "title": "Work Packages",
    "section": "Societal and Environmental Well-being",
    "text": "Societal and Environmental Well-being\nImpact on Work and Skills\nInvestigate impact on work arrangements\nImpact on Society at large or Democracy\nSolicit citizen feedback"
  },
  {
    "objectID": "wp_tasks.html#accountability-1",
    "href": "wp_tasks.html#accountability-1",
    "title": "Work Packages",
    "section": "Accountability",
    "text": "Accountability\nAuditability\nFacilitate auditability"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight-2",
    "href": "wp_tasks.html#human-agency-and-oversight-2",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nDefine epistemic authority\nHuman oversight\nManage patient expectations"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety-2",
    "href": "wp_tasks.html#technical-robustness-and-safety-2",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nGeneral safety\nAssess risk of use"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance-3",
    "href": "wp_tasks.html#privacy-and-data-governance-3",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nData governance\nAcquire informed consent"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness-2",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness-2",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nRepresent diversity in training data"
  },
  {
    "objectID": "wp_tasks.html#accountability-2",
    "href": "wp_tasks.html#accountability-2",
    "title": "Work Packages",
    "section": "Accountability",
    "text": "Accountability\nTradeoffs/ Risk-management\nCollect post-prediction feedback"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight-3",
    "href": "wp_tasks.html#human-agency-and-oversight-3",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nDefine epistemic authority\nHuman oversight\nManage patient expectations"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety-3",
    "href": "wp_tasks.html#technical-robustness-and-safety-3",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nGeneral safety\nAssess risk of use"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance-4",
    "href": "wp_tasks.html#privacy-and-data-governance-4",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nData governance\nAcquire informed consent"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness-3",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness-3",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nRepresent diversity in training data\nAccountability\nTradeoffs/ Risk-management\nCollect post-prediction feedback"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight-4",
    "href": "wp_tasks.html#human-agency-and-oversight-4",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nDefine epistemic authority\nHuman oversight\nManage patient expectations"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety-4",
    "href": "wp_tasks.html#technical-robustness-and-safety-4",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nGeneral safety\nAssess risk of use"
  },
  {
    "objectID": "wp_tasks.html#privacy-and-data-governance-5",
    "href": "wp_tasks.html#privacy-and-data-governance-5",
    "title": "Work Packages",
    "section": "Privacy and Data Governance",
    "text": "Privacy and Data Governance\nData governance\nAcquire informed consent"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness-4",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness-4",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nRepresent diversity in training data"
  },
  {
    "objectID": "wp_tasks.html#accountability-3",
    "href": "wp_tasks.html#accountability-3",
    "title": "Work Packages",
    "section": "Accountability",
    "text": "Accountability\nTradeoffs/ Risk-management\nCollect post-prediction feedback"
  },
  {
    "objectID": "wp_tasks.html#human-agency-and-oversight-5",
    "href": "wp_tasks.html#human-agency-and-oversight-5",
    "title": "Work Packages",
    "section": "Human Agency and Oversight",
    "text": "Human Agency and Oversight\nHuman agency and autonomy\nFoster patient autonomy"
  },
  {
    "objectID": "wp_tasks.html#technical-robustness-and-safety-5",
    "href": "wp_tasks.html#technical-robustness-and-safety-5",
    "title": "Work Packages",
    "section": "Technical Robustness and Safety",
    "text": "Technical Robustness and Safety\nResilience to attack and security\nComply with cybersecurity law\nGeneral safety\nCommunicate risks to patients\nReliability and reproducibility\nEnsure continuous adaptation"
  },
  {
    "objectID": "wp_tasks.html#transparency-2",
    "href": "wp_tasks.html#transparency-2",
    "title": "Work Packages",
    "section": "Transparency",
    "text": "Transparency\nCommunication\nStandardize training materials"
  },
  {
    "objectID": "wp_tasks.html#diversity-non-discrimination-and-fairness-5",
    "href": "wp_tasks.html#diversity-non-discrimination-and-fairness-5",
    "title": "Work Packages",
    "section": "Diversity, Non-discrimination and Fairness",
    "text": "Diversity, Non-discrimination and Fairness\nAvoidance of unfair bias\nAssess fairness across use-setting\nImplement fairness reporting system\nAccessibility and universal design\nAssess financial risk of unfair design"
  },
  {
    "objectID": "wp_tasks.html#accountability-4",
    "href": "wp_tasks.html#accountability-4",
    "title": "Work Packages",
    "section": "Accountability",
    "text": "Accountability\nTradeoffs/ Risk-management\nConduct budget impact analysis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Plan for Ethical and Trustworthy Design of the STRATIF-AI project",
    "section": "",
    "text": "Overview\nThis framework has been developed in concordance with requirements within the EU Horizon Project STRATIF-AI [Grant No. 101080875].\n\n\nBackground\nThe application of artificial intelligence (AI) in healthcare poses ethical risks. Dedicated efforts are essential to ensure that AI systems in healthcare adhere to principles of lawfulness, ethics, and robustness. We have developed a plan which outlines steps to mitigate ethical risks and increase trustworthiness throughout the lifecycle of the STRATIF-AI project. We draw on interdisciplinary expertise and align our approach with three core strategies:\n(1) Operationalization: Existing guidelines for AI development often provide broad, high-level principles, which are suitable for a wide range of AI systems. High-level principles must be translated to actionable steps that are tailored to the specific traits of individual AI systems. Our approach is designed to ensure that ethical principles do not remain theoretical concepts—but are instead effectively embedded into the design, implementation, and continuous management of the STRATIF-AI system.\n(2) Co-creation: We have adopted a co-creation process to ensure equitable development of solutions. The content for this manual has been developed in collaboration with key stakeholders within the STRATIF-AI project, including clinicians, data scientists, medical researchers, representatives from patient organizations, and project coordinators. Engaging diverse stakeholders allows us to thoroughly assess the risks and benefits associated with specific requirements. The collaborative process fosters the creation of ethical requirements that are not only necessary and feasible but also auditable, thus contributing to the overall integrity and reliability of the STRATIF-AI system.\n(3) Anticipation: The STRATIF-AI project introduces several novel technological solutions. Novel challenges may fall outside the scope of existing ethical guidelines, and may thus be difficult to address by simply adhering to current regulations or previously published frameworks. To help mitigate novel ethical risks, we pay close attention in our workshops and research to issues or concerns relevant to digital twins in healthcare which may be yet unprecedented.\nOverall, our ethical plan has been designed to facilitate the early identification of potential ethical risks of the STRATIF-AI project and ultimately enhance the system’s trustworthiness and societal impact."
  }
]